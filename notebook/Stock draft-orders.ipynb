{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [],
            "values": [],
            "yLabel": "",
            "xLabel": "",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": {},
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "inventory_data = spark.read\\\n",
        "    .format(\"cosmos.olap\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDb\")\\\n",
        "    .option(\"spark.cosmos.container\", \"inventory\")\\\n",
        "    .load()\n",
        "inventory_data = inventory_data.drop(\"_rid\",\"_ts\",\"_etag\")\n",
        "display(inventory_data.limit(2))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 2,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "STORE_ID"
            ],
            "values": [
              "STORE_STOCK"
            ],
            "yLabel": "STORE_STOCK",
            "xLabel": "STORE_ID",
            "aggregation": "SUM",
            "aggByBackend": false,
            "isValid": true,
            "inValidMsg": null,
            "stacked": false
          },
          "aggData": {
            "STORE_STOCK": {
              "12": 4,
              "13": 4,
              "14": 35
            }
          },
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "store_pots_stock = inventory_data[inventory_data[\"PRODUCT_NAME\"] == \"Pots\"]\\\n",
        "    .groupBy(\"PRODUCT_NAME\",\"STORE_ID\")\\\n",
        "    .sum(\"STOCK\")\\\n",
        "    .withColumnRenamed(\"SUM(STOCK)\", \"STORE_STOCK\")\n",
        "    \n",
        "display(store_pots_stock)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "sales_data = spark.read\\\n",
        "    .format(\"cosmos.olap\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDb\")\\\n",
        "    .option(\"spark.cosmos.container\", \"sales\")\\\n",
        "    .load()\n",
        "\n",
        "sales_data = sales_data.withColumn(\"QUANTITY\", sales_data[\"QUANTITY\"].cast(IntegerType()))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 2,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "STORE_ID"
            ],
            "values": [
              "STORE_STOCK",
              "AVG_SALES"
            ],
            "yLabel": "STORE_STOCK,AVG_SALES",
            "xLabel": "STORE_ID",
            "aggregation": "SUM",
            "aggByBackend": false,
            "isValid": true,
            "inValidMsg": null
          },
          "aggData": {
            "STORE_STOCK": {
              "12": 4,
              "13": 4
            },
            "AVG_SALES": {
              "12": 5,
              "13": 1
            }
          },
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "avg_sales = sales_data.groupBy(\"PRODUCT_NAME\",\"STORE_ID\")\\\n",
        "    .avg(\"QUANTITY\")\\\n",
        "    .withColumnRenamed(\"avg(QUANTITY)\", \"AVG_SALES\")\n",
        "\n",
        "stock = inventory_data.groupBy(\"PRODUCT_NAME\",\"STORE_ID\")\\\n",
        "    .sum(\"STOCK\")\\\n",
        "    .withColumnRenamed(\"SUM(STOCK)\", \"STORE_STOCK\")\\\n",
        "\n",
        "draft_orders = stock.join(avg_sales, on=['STORE_ID','PRODUCT_NAME'], how='inner')\\\n",
        "    .orderBy(\"AVG_SALES\", ascending=False)\n",
        "\n",
        "draft_orders = draft_orders.where(\"STORE_STOCK < 20\")\n",
        "display(draft_orders)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "PRODUCT_NAME"
            ],
            "values": [
              "STORE_ID"
            ],
            "yLabel": "STORE_ID",
            "xLabel": "PRODUCT_NAME",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": {
            "STORE_ID": {
              "Pots": 25
            }
          },
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "def should_order(stock, sales):\n",
        "  if   stock < sales: \n",
        "      return 'Y'\n",
        "  else:\n",
        "      return 'N'\n",
        "\n",
        "should_order = F.udf(should_order, StringType())\n",
        "draft_orders = draft_orders.withColumn(\"SHOULD_ORDER\", should_order(draft_orders[\"STORE_STOCK\"],draft_orders[\"AVG_SALES\"])) \n",
        "display(draft_orders)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Write a Spark DataFrame into a Cosmos DB container\n",
        "# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
        "\n",
        "draft_orders.write\\\n",
        "    .format(\"cosmos.oltp\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDb\")\\\n",
        "    .option(\"spark.cosmos.container\", \"draftorders\")\\\n",
        "    .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\n",
        "    .mode('append')\\\n",
        "    .save()"
      ],
      "attachments": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "sessionKeepAliveTimeout": 30
  },
  "nbformat": 4,
  "nbformat_minor": 2
}